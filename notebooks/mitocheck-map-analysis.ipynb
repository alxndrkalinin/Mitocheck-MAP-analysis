{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import logging\n",
                "import pathlib\n",
                "from typing import Optional\n",
                "\n",
                "from copairs.map import run_pipeline\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pycytominer import feature_select\n",
                "\n",
                "# imports src\n",
                "sys.path.append(\"../\")\n",
                "from src import utils\n",
                "\n",
                "# setting up logger\n",
                "logging.basicConfig(\n",
                "    filename=\"map_analysis_testing.log\",\n",
                "    level=logging.DEBUG,\n",
                "    format=\"%(levelname)s:%(asctime)s:%(name)s:%(message)s\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper functions\n",
                "Set of helper functions to help out throughout the notebook"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Helper function\n",
                "def shuffle_meta_labels(\n",
                "    dataset: pd.DataFrame, target_col: str, seed: Optional[int] = 0\n",
                ") -> pd.DataFrame:\n",
                "    \"\"\"shuffles labels or values within a single selected column\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    dataset : pd.DataFrame\n",
                "        dataframe containing the dataset\n",
                "\n",
                "    target_col : str\n",
                "        Column to select in order to conduct the shuffling\n",
                "\n",
                "    seed : int\n",
                "        setting random seed\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    pd.DataFrame\n",
                "        shuffled dataset\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    TypeError\n",
                "        raised if incorrect types are provided\n",
                "    \"\"\"\n",
                "    # setting seed\n",
                "    np.random.seed(seed)\n",
                "\n",
                "    # type checking\n",
                "    if not isinstance(target_col, str):\n",
                "        raise TypeError(\"'target_col' must be a string type\")\n",
                "    if not isinstance(dataset, pd.DataFrame):\n",
                "        raise TypeError(\"'dataset' must be a pandas dataframe\")\n",
                "\n",
                "    # selecting column, shuffle values within column, add to dataframe\n",
                "    dataset[target_col] = np.random.permutation(dataset[target_col].values)\n",
                "    return dataset\n",
                "\n",
                "\n",
                "def shuffle_features(feature_vals: np.array, seed: Optional[int] = 0) -> np.array:\n",
                "    \"\"\"suffles all values within feature space\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    feature_vals : np.array\n",
                "        shuffled\n",
                "\n",
                "    seed : Optional[int]\n",
                "        setting random seed\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    np.array\n",
                "        Returns shuffled values within the feature space\n",
                "\n",
                "    Raises\n",
                "    ------\n",
                "    TypeError\n",
                "        Raised if a numpy array is not provided\n",
                "    \"\"\"\n",
                "    # setting seed\n",
                "    np.random.seed(seed)\n",
                "\n",
                "    # shuffle given array\n",
                "    if not isinstance(feature_vals, np.ndarray):\n",
                "        raise TypeError(\"'feature_vals' must be a numpy array\")\n",
                "    if feature_vals.ndim != 2:\n",
                "        raise TypeError(\"'feature_vals' must be a 2x2 matrix\")\n",
                "\n",
                "    # creating a copy for feature vales to prevent overwriting of global variables\n",
                "    feature_vals = np.copy(feature_vals)\n",
                "\n",
                "    # shuffling feature space\n",
                "    n_cols = feature_vals.shape[1]\n",
                "    for col_idx in range(0, n_cols):\n",
                "        # selecting column, shuffle, and update:\n",
                "        feature_vals[:, col_idx] = np.random.permutation(feature_vals[:, col_idx])\n",
                "\n",
                "    return feature_vals"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setting up Paths and loading data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# parameters\n",
                "training_singlecell_data = pathlib.Path(\"../data/raw/training_data.csv.gz\").resolve(\n",
                "    strict=True\n",
                ")\n",
                "neg_control_data = pathlib.Path(\n",
                "    \"../data/raw/normalized_data/negative_control_data.csv.gz\"\n",
                ").resolve(strict=True)\n",
                "\n",
                "# output directories\n",
                "map_out_dir = pathlib.Path(\"../data/processed/mAP_scores/\")\n",
                "map_out_dir.mkdir(parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# training_sc_data = pd.read_parquet(\"../data/processed/training_sc_data.parquet\")\n",
                "# neg_control_sc_data = pd.read_parquet(\"../data/processed/neg_control_sc_data.parquet\")\n",
                "training_sc_data = pd.read_csv(training_singlecell_data).drop(\"Unnamed: 0\", axis=1)\n",
                "neg_control_sc_data = pd.read_csv(neg_control_data)\n",
                "\n",
                "# adding the Mitocheck_Phenotypic_Class into the controls  and labels\n",
                "neg_control_sc_data.insert(0, \"Mitocheck_Phenotypic_Class\", \"neg_control\")\n",
                "\n",
                "# adding control labels into the dataset\n",
                "training_sc_data.insert(1, \"Metadata_is_control\", 0)\n",
                "neg_control_sc_data.insert(1, \"Metadata_is_control\", 1)\n",
                "\n",
                "# droping column from trainign data since it does not exist in the controls\n",
                "training_sc_data = training_sc_data.drop(\"Metadata_Object_Outline\", axis=1)\n",
                "\n",
                "\n",
                "print(\"control shape:\", neg_control_sc_data.shape)\n",
                "print(\"training shape:\", training_sc_data.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Applying Pycytominer Selected features data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# applying cytominer feature selection trianing data\n",
                "cp_cols = [\n",
                "    colname for colname in training_sc_data.columns if colname.startswith(\"CP__\")\n",
                "]\n",
                "\n",
                "# # extracting only CP features\n",
                "train_meta, train_features = utils.split_data(training_sc_data, dataset=\"CP\")\n",
                "cp_data = pd.concat([train_meta, pd.DataFrame(train_features)], axis=1)\n",
                "cp_data.columns = train_meta.columns.tolist() + cp_cols\n",
                "\n",
                "# applying pycytominer feature select\n",
                "# had to specify the feature names since the defaults did not match\n",
                "pycytm_cp_training_feats_df = feature_select(cp_data, features=cp_cols)\n",
                "pycytm_cp_training_feats_df = pycytm_cp_training_feats_df[\n",
                "    [\n",
                "        cols\n",
                "        for cols in pycytm_cp_training_feats_df.columns.tolist()\n",
                "        if cols.startswith(\"CP__\")\n",
                "    ]\n",
                "]\n",
                "del cp_data\n",
                "\n",
                "# now update loaded dataset with pycytominer selected features to trainin dataset\n",
                "# remove old CP features and added new pycytominer selected CP_features\n",
                "training_sc_data = training_sc_data[\n",
                "    [col for col in training_sc_data.columns.tolist() if not col.startswith(\"CP__\")]\n",
                "]\n",
                "training_sc_data = pd.concat([training_sc_data, pycytm_cp_training_feats_df], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# applying cytominer feature selection negative control data\n",
                "cp_cols = [\n",
                "    colname for colname in neg_control_sc_data.columns if colname.startswith(\"CP__\")\n",
                "]\n",
                "\n",
                "# extracting only CP features\n",
                "neg_control_meta, neg_control_features = utils.split_data(\n",
                "    neg_control_sc_data, dataset=\"CP\"\n",
                ")\n",
                "cp_data = pd.concat([neg_control_meta, pd.DataFrame(neg_control_features)], axis=1)\n",
                "cp_data.columns = neg_control_meta.columns.tolist() + cp_cols\n",
                "\n",
                "# applying pycytominer feature select\n",
                "# had to specify the feature names since the defaults did not match\n",
                "pycytm_cp_training_feats_df = feature_select(cp_data, features=cp_cols)\n",
                "pycytm_cp_training_feats_df = pycytm_cp_training_feats_df[\n",
                "    [\n",
                "        cols\n",
                "        for cols in pycytm_cp_training_feats_df.columns.tolist()\n",
                "        if cols.startswith(\"CP__\")\n",
                "    ]\n",
                "]\n",
                "del cp_data\n",
                "\n",
                "# now update loaded dataset with pycytominer selected features to trainin dataset\n",
                "# remove old CP features and added new pycytominer selected features\n",
                "neg_control_sc_data = neg_control_sc_data[\n",
                "    [col for col in neg_control_sc_data.columns.tolist() if not col.startswith(\"CP__\")]\n",
                "]\n",
                "neg_control_sc_data = pd.concat(\n",
                "    [neg_control_sc_data, pycytm_cp_training_feats_df], axis=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### mAP Pipeline Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pos_sameby = [\n",
                "    \"Mitocheck_Phenotypic_Class\",\n",
                "]\n",
                "pos_diffby = [\"Cell_UUID\"]\n",
                "\n",
                "neg_sameby = []\n",
                "neg_diffby = [\"Mitocheck_Phenotypic_Class\"]\n",
                "\n",
                "null_size = 1000\n",
                "batch_size = 1000\n",
                "\n",
                "# number of resampling\n",
                "n_resamples = 10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running mAP Pipeline on regular dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# storing all map results based on postiive and negative controls and feature types\n",
                "logging.info(\"Running mAP pipeline with regular dataset\")\n",
                "map_results_neg_cp = []\n",
                "map_results_neg_dp = []\n",
                "map_results_neg_cp_dp = []\n",
                "\n",
                "# running process\n",
                "# for loop selects one single phenotype\n",
                "# then splits the data into metadata and raw feature values\n",
                "# two different groups that contains 3 splits caused by the types of features\n",
                "# applie the copairs pipeline\n",
                "for phenotype in list(training_sc_data[\"Mitocheck_Phenotypic_Class\"].unique()):\n",
                "    # select training dataset based on phenotype\n",
                "    selected_training = training_sc_data.loc[\n",
                "        training_sc_data[\"Mitocheck_Phenotypic_Class\"] == phenotype\n",
                "    ]\n",
                "    n_entries_training = selected_training.shape[0]\n",
                "\n",
                "    # This will generated 100 values [0..100] as seed values\n",
                "    # This will occur per phenotype\n",
                "    for seed in range(0, n_resamples):\n",
                "        # concatenate to positive and negative control\n",
                "        # selecting around 0.015% of the control data, that's around 117 cells\n",
                "        training_w_neg = pd.concat(\n",
                "            [\n",
                "                selected_training,\n",
                "                neg_control_sc_data.sample(frac=0.010, random_state=seed).iloc[\n",
                "                    :n_entries_training\n",
                "                ],\n",
                "            ]\n",
                "        )\n",
                "\n",
                "        # spliting metadata and raw feature values\n",
                "        logging.info(\"splitting data set into metadata and raw feature values\")\n",
                "        negative_training_cp_meta, negative_training_cp_feats = utils.split_data(\n",
                "            training_w_neg, dataset=\"CP\"\n",
                "        )\n",
                "        negative_training_dp_meta, negative_training_dp_feats = utils.split_data(\n",
                "            training_w_neg, dataset=\"DP\"\n",
                "        )\n",
                "        negative_training_cp_dp_meta, negative_training_cp_dp_feats = utils.split_data(\n",
                "            training_w_neg, dataset=\"CP_and_DP\"\n",
                "        )\n",
                "\n",
                "        # placing under \"try\" block as some phenotype may raise \"DivisionByZeroError\"\n",
                "        try:\n",
                "            # execute pipeline on negative control with trianing dataset with cp features\n",
                "            logging.info(f\"Running pipeline on CP features using {phenotype} phenotype\")\n",
                "            cp_negative_training_result = run_pipeline(\n",
                "                meta=negative_training_cp_meta,\n",
                "                feats=negative_training_cp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding columsn\n",
                "            cp_negative_training_result[\"shuffled\"] = \"non-shuffled\"\n",
                "            cp_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            map_results_neg_cp.append(cp_negative_training_result)\n",
                "\n",
                "            # execute pipeline on negative control with trianing dataset with dp features\n",
                "            logging.info(f\"Running pipeline on DP features using {phenotype} phenotype\")\n",
                "            dp_negative_training_result = run_pipeline(\n",
                "                meta=negative_training_dp_meta,\n",
                "                feats=negative_training_dp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            dp_negative_training_result[\"shuffled\"] = \"non-shuffled\"\n",
                "            dp_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            map_results_neg_dp.append(dp_negative_training_result)\n",
                "\n",
                "            # execute pipeline on negative control with trianing dataset with cp_dp features\n",
                "            logging.info(\n",
                "                f\"Running pipeline on CP and DP features using {phenotype} phenotype\"\n",
                "            )\n",
                "            cp_dp_negative_training_result = run_pipeline(\n",
                "                meta=negative_training_cp_dp_meta,\n",
                "                feats=negative_training_cp_dp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            cp_dp_negative_training_result[\"shuffled\"] = \"non-shuffled\"\n",
                "            cp_dp_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            map_results_neg_cp_dp.append(cp_dp_negative_training_result)\n",
                "        except ZeroDivisionError as e:\n",
                "            logging.warning(f\"{e} captured on phenotye: {phenotype}. Skipping\")\n",
                "            continue\n",
                "\n",
                "\n",
                "# concatenating all datasets\n",
                "pd.concat(map_results_neg_cp).to_csv(\n",
                "    map_out_dir / \"cp_sc_mAP_scores_regular.csv\", index=False\n",
                ")\n",
                "pd.concat(map_results_neg_dp).to_csv(\n",
                "    map_out_dir / \"dp_sc_mAP_scores_regular.csv\", index=False\n",
                ")\n",
                "pd.concat(map_results_neg_cp_dp).to_csv(\n",
                "    map_out_dir / \"cp_dp_sc_mAP_scores_regular.csv\", index=False\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running MAP Pipeline with shuffled phenotype labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging.info(\"Running mAP pipeline with shuffled phenotype labeled data\")\n",
                "\n",
                "# storing generated mAP pipline results seperated by feature\n",
                "shuffled_labels_map_results_neg_cp = []\n",
                "shuffled_labels_map_results_neg_dp = []\n",
                "shuffled_labels_map_results_neg_cp_dp = []\n",
                "\n",
                "# running process\n",
                "# for loop selects one single phenotype\n",
                "# then splits the data into metadata and raw feature values\n",
                "# two different groups that contains 3 splits caused by the types of features\n",
                "# applie the copairs pipeline\n",
                "for phenotype in list(training_sc_data[\"Mitocheck_Phenotypic_Class\"].unique()):\n",
                "    # select training dataset based on phenotype\n",
                "    logging.info(f\"Phenotype selected: {phenotype}\")\n",
                "    selected_training = training_sc_data.loc[\n",
                "        training_sc_data[\"Mitocheck_Phenotypic_Class\"] == phenotype\n",
                "    ]\n",
                "    n_entries_training = selected_training.shape[0]\n",
                "\n",
                "    # This will generated 100 values [0..100] as seed values\n",
                "    # seed values will\n",
                "    for seed in range(0, n_resamples):\n",
                "        # setting seed\n",
                "        logging.info(\n",
                "            f\"Running MAP Pipeline with shuffled data. Setting random seed too: {seed}\"\n",
                "        )\n",
                "        np.random.seed(seed)\n",
                "\n",
                "        # Below, we are running the same test, but we are shuffling the phenotypes\n",
                "        logging.info(\n",
                "            \"Shuffling data based on the Mitocheck_Phenotypic_Class (phenotype) labels\"\n",
                "        )\n",
                "\n",
                "        # concatenate to positive and negative control and shuffle labels\n",
                "        training_w_neg = pd.concat(\n",
                "            [\n",
                "                selected_training,\n",
                "                neg_control_sc_data.sample(frac=0.010, random_state=seed).iloc[\n",
                "                    :n_entries_training\n",
                "                ],\n",
                "            ]\n",
                "        )\n",
                "        training_w_neg = shuffle_meta_labels(\n",
                "            dataset=training_w_neg, target_col=\"Mitocheck_Phenotypic_Class\", seed=seed\n",
                "        )\n",
                "\n",
                "        # splitting metadata labeled shuffled data\n",
                "        logging.info(\"splitting shuffled data set into metadata and raw feature values\")\n",
                "        (\n",
                "            shuffled_negative_training_cp_meta,\n",
                "            shuffled_negative_training_cp_feats,\n",
                "        ) = utils.split_data(training_w_neg, dataset=\"CP\")\n",
                "        (\n",
                "            shuffled_negative_training_dp_meta,\n",
                "            shuffled_negative_training_dp_feats,\n",
                "        ) = utils.split_data(training_w_neg, dataset=\"DP\")\n",
                "        (\n",
                "            shuffled_negative_training_cp_dp_meta,\n",
                "            shuffled_negative_training_cp_dp_feats,\n",
                "        ) = utils.split_data(training_w_neg, dataset=\"CP_and_DP\")\n",
                "\n",
                "        try:\n",
                "            # execute pipeline on negative control with trianing dataset with cp features\n",
                "            logging.info(\n",
                "                f\"Running pipeline on CP features using {phenotype} phenotype, data is shuffled by phenoptype labels\"\n",
                "            )\n",
                "            shuffled_cp_negative_training_result = run_pipeline(\n",
                "                meta=shuffled_negative_training_cp_meta,\n",
                "                feats=shuffled_negative_training_cp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            shuffled_cp_negative_training_result[\"shuffled\"] = \"phenotype_shuffled\"\n",
                "            shuffled_cp_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            shuffled_labels_map_results_neg_cp.append(\n",
                "                shuffled_cp_negative_training_result\n",
                "            )\n",
                "\n",
                "            # execute pipeline on negative control with trianing dataset with dp features\n",
                "            logging.info(\n",
                "                f\"Running pipeline on DP features using {phenotype} phenotype, data is shuffled by phenoptype labels\"\n",
                "            )\n",
                "            shuffled_dp_negative_training_result = run_pipeline(\n",
                "                meta=shuffled_negative_training_dp_meta,\n",
                "                feats=shuffled_negative_training_dp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            shuffled_dp_negative_training_result[\"shuffled\"] = \"phenotype_shuffled\"\n",
                "            shuffled_dp_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            shuffled_labels_map_results_neg_dp.append(\n",
                "                shuffled_dp_negative_training_result\n",
                "            )\n",
                "\n",
                "            # execute pipeline on negative control with trianing dataset with cp_dp features\n",
                "            logging.info(\n",
                "                f\"Running pipeline on CP and DP features using {phenotype} phenotype, data is shuffled by phenoptype labels\"\n",
                "            )\n",
                "            shuffled_cp_dp_negative_training_result = run_pipeline(\n",
                "                meta=shuffled_negative_training_cp_dp_meta,\n",
                "                feats=shuffled_negative_training_cp_dp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            shuffled_cp_dp_negative_training_result[\"shuffled\"] = \"phenotype_shuffled\"\n",
                "            shuffled_cp_dp_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            shuffled_labels_map_results_neg_cp_dp.append(\n",
                "                shuffled_cp_dp_negative_training_result\n",
                "            )\n",
                "        except ZeroDivisionError as e:\n",
                "            logging.warning(f\"{e} captured on phenotye: {phenotype}. Skipping\")\n",
                "            continue\n",
                "\n",
                "# saving to csv\n",
                "pd.concat(shuffled_labels_map_results_neg_cp).to_csv(\n",
                "    map_out_dir / \"cp_sc_mAP_scores_label_shuffled.csv\", index=False\n",
                ")\n",
                "pd.concat(shuffled_labels_map_results_neg_dp).to_csv(\n",
                "    map_out_dir / \"dp_sc_mAP_scores_label_shuffled.csv\", index=False\n",
                ")\n",
                "pd.concat(shuffled_labels_map_results_neg_cp_dp).to_csv(\n",
                "    map_out_dir / \"cp_dp_sc_mAP_scores_label_shuffled.csv\", index=False\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running MAP Pipeline with shuffled feature space "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging.info(\"Running mAP pipeline with shuffled feature space data\")\n",
                "shuffled_feat_map_results_neg_cp = []\n",
                "shuffled_feat_map_results_neg_dp = []\n",
                "shuffled_feat_map_results_neg_cp_dp = []\n",
                "\n",
                "# running process\n",
                "# for loop selects one single phenotype\n",
                "# then splits the data into metadata and raw feature values\n",
                "# two different groups that contains 3 splits caused by the types of features\n",
                "# applie the copairs pipeline\n",
                "for phenotype in list(training_sc_data[\"Mitocheck_Phenotypic_Class\"].unique()):\n",
                "    # select training dataset based on phenotype\n",
                "    selected_training = training_sc_data.loc[\n",
                "        training_sc_data[\"Mitocheck_Phenotypic_Class\"] == phenotype\n",
                "    ]\n",
                "    n_entries_training = selected_training.shape[0]\n",
                "\n",
                "    # This will generated 100 values [0..100] as seed values\n",
                "    # seed values will\n",
                "    for seed in range(0, n_resamples):\n",
                "        # setting seed\n",
                "        logging.info(\n",
                "            f\"Running MAP Pipeline with shuffled data. Setting random seed too: {seed}\"\n",
                "        )\n",
                "        np.random.seed(seed)\n",
                "\n",
                "        # Below, we are running the same test, but we are shuffling the phenotypes\n",
                "        logging.info(\"Shuffling data based on the feature space\")\n",
                "        training_w_neg = pd.concat(\n",
                "            [\n",
                "                selected_training,\n",
                "                neg_control_sc_data.sample(frac=0.010, random_state=seed).iloc[\n",
                "                    :n_entries_training\n",
                "                ],\n",
                "            ]\n",
                "        )\n",
                "\n",
                "        # split the shuffled dataset\n",
                "        # spliting metadata and raw feature values\n",
                "        logging.info(\"splitting shuffled data set into metadata and raw feature values\")\n",
                "        (\n",
                "            shuffled_negative_training_cp_meta,\n",
                "            shuffled_negative_training_cp_feats,\n",
                "        ) = utils.split_data(training_w_neg, dataset=\"CP\")\n",
                "        (\n",
                "            shuffled_negative_training_dp_meta,\n",
                "            shuffled_negative_training_dp_feats,\n",
                "        ) = utils.split_data(training_w_neg, dataset=\"DP\")\n",
                "        (\n",
                "            shuffled_negative_training_cp_dp_meta,\n",
                "            shuffled_negative_training_cp_dp_feats,\n",
                "        ) = utils.split_data(training_w_neg, dataset=\"CP_and_DP\")\n",
                "\n",
                "        # shuffling the features, this will overwrite the generated feature space from above with the shuffled one\n",
                "        shuffled_negative_training_cp_feats = shuffle_features(\n",
                "            feature_vals=shuffled_negative_training_cp_feats, seed=seed\n",
                "        )\n",
                "        shuffled_negative_training_dp_feats = shuffle_features(\n",
                "            feature_vals=shuffled_negative_training_dp_feats, seed=seed\n",
                "        )\n",
                "        shuffled_negative_training_cp_dp_feats = shuffle_features(\n",
                "            feature_vals=shuffled_negative_training_cp_dp_feats, seed=seed\n",
                "        )\n",
                "\n",
                "        try:\n",
                "            # execute pipeline on negative control with trianing dataset with cp features\n",
                "            logging.info(\n",
                "                f\"Running pipeline on CP features using {phenotype} phenotype, feature space is shuffled\"\n",
                "            )\n",
                "            shuffled_cp_feat_negative_training_result = run_pipeline(\n",
                "                meta=shuffled_negative_training_cp_meta,\n",
                "                feats=shuffled_negative_training_cp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            shuffled_cp_feat_negative_training_result[\"shuffled\"] = \"features_shuffled\"\n",
                "            shuffled_cp_feat_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            shuffled_feat_map_results_neg_cp.append(\n",
                "                shuffled_cp_feat_negative_training_result\n",
                "            )\n",
                "\n",
                "            # execute pipeline on negative control with trianing dataset with dp features\n",
                "            logging.info(\n",
                "                f\"Running pipeline on DP features using {phenotype} phenotype, feature space is shuffled\"\n",
                "            )\n",
                "            shuffled_dp_feat_negative_training_result = run_pipeline(\n",
                "                meta=shuffled_negative_training_dp_meta,\n",
                "                feats=shuffled_negative_training_dp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            shuffled_dp_feat_negative_training_result[\"shuffled\"] = \"features_shuffled\"\n",
                "            shuffled_dp_feat_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            shuffled_feat_map_results_neg_dp.append(\n",
                "                shuffled_dp_feat_negative_training_result\n",
                "            )\n",
                "\n",
                "            # execute pipeline on negative control with trianing dataset with cp_dp features\n",
                "            logging.info(\n",
                "                f\"Running pipeline on CP and DP features using {phenotype} phenotype, feature space is shuffled\"\n",
                "            )\n",
                "            shuffled_cp_dp_feat_negative_training_result = run_pipeline(\n",
                "                meta=shuffled_negative_training_cp_dp_meta,\n",
                "                feats=shuffled_negative_training_cp_dp_feats,\n",
                "                pos_sameby=pos_sameby,\n",
                "                pos_diffby=pos_diffby,\n",
                "                neg_sameby=neg_sameby,\n",
                "                neg_diffby=neg_diffby,\n",
                "                batch_size=batch_size,\n",
                "                null_size=null_size,\n",
                "            )\n",
                "\n",
                "            # adding shuffle label column\n",
                "            shuffled_cp_dp_feat_negative_training_result[\n",
                "                \"shuffled\"\n",
                "            ] = \"features_shuffled\"\n",
                "            shuffled_cp_dp_feat_negative_training_result[\"seed_val\"] = seed\n",
                "\n",
                "            # append to list\n",
                "            shuffled_feat_map_results_neg_cp_dp.append(\n",
                "                shuffled_cp_dp_feat_negative_training_result\n",
                "            )\n",
                "        except ZeroDivisionError as e:\n",
                "            logging.warning(f\"{e} captured on phenotype: {phenotype}. Skipping\")\n",
                "            continue\n",
                "\n",
                "\n",
                "# saving to csv\n",
                "pd.concat(shuffled_feat_map_results_neg_cp).to_csv(\n",
                "    map_out_dir / \"cp_sc_mAP_scores_feat_shuffled.csv\", index=False\n",
                ")\n",
                "pd.concat(shuffled_feat_map_results_neg_dp).to_csv(\n",
                "    map_out_dir / \"dp_sc_mAP_scores_feat_shuffled.csv\", index=False\n",
                ")\n",
                "pd.concat(shuffled_feat_map_results_neg_cp_dp).to_csv(\n",
                "    map_out_dir / \"cp_dp_sc_mAP_scores_feat_shuffled.csv\", index=False\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "map",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
